# Multi-Disorder Mental Health AI Diagnosis
**Tri-Modal, Severity-Aware Fusion for Depression and PTSD**

[![Python](https://img.shields.io/badge/python-3.9%2B-blue.svg)](#)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.x-EE4C2C.svg)](#)
[![License](https://img.shields.io/badge/license-UNSPECIFIED-lightgrey.svg)](#)

This repo contains a fast, reproducible trainer that fuses **Text (768)** + **Audio (256)** + **Face (512)** features into a **1536-D** vector and trains **seed-ensembled XGBoost** with stratified K-fold CV.  
It outputs paper-ready logs such as `logs_paper/summary_all.csv`.

---

## âœ¨ Whatâ€™s inside
- **`fast_multimodal.py`** â€“ end-to-end training (feature build â†’ CV â†’ seed ensemble â†’ logs)
- **Tri-modal features**
  - Text: `all-mpnet-base-v2` mean pooled (768-D, cached per PID)
  - Audio: 64-mel log-spectrogram stats + deltas (256-D)
  - Face: OpenFace numeric columns, mean+std (512-D)
- **Outputs**: `summary_all.csv`, `summary_all.json`, out-of-fold NPZs for figures (PR/ROC/CM)

---

## ğŸ› ï¸ Setup

### 1) Create env & install deps
```bash
python -m venv .venv
source .venv/bin/activate          # Windows: .venv\Scripts\activate
pip install -U pip wheel
pip install -r requirements.txt


Datasets you need

We train on E-DAIC and DAIC-WOZ. Obtain access from the official providers and place the data locally.

Required CSVs (repo root by default)

metadata_mapped.csv (must include: Participant_ID, PTSD Severity, and optionally PHQ_Score)

Detailed_PHQ8_Labels.csv (must include: Participant_ID, PHQ_8Total)

The script prefers PHQ_8Total for depression; falls back to PHQ_Score if missing. PTSD severity is taken from metadata_mapped.csv.

Expected folder layout

You can keep the two datasets in two separate roots (names customizable via flags):

repo/
â”œâ”€ fast_multimodal.py
â”œâ”€ requirements.txt
â”œâ”€ run_paper.sh
â”œâ”€ extractor.py
â”œâ”€ controller.py
â”œâ”€ metadata_mapped.csv
â”œâ”€ Detailed_PHQ8_Labels.csv
â”œâ”€ data/                      # E-DAIC root (example)
â”‚  â”œâ”€ 300_P/
â”‚  â”‚  â”œâ”€ 300_AUDIO.wav
â”‚  â”‚  â”œâ”€ 300_TRANSCRIPT.csv               # any *transcript*.csv works
â”‚  â”‚  â”œâ”€ 300_openface_clnf.csv            # any PID + (clnf|openface|au|gaze|pose)
â”‚  â”‚  â””â”€ ...
â”‚  â””â”€ ...
â””â”€ data_daicwoz/              # DAIC-WOZ root (example)
   â”œâ”€ 302_P/
   â”‚  â”œâ”€ 302_AUDIO.wav
   â”‚  â”œâ”€ 302_TRANSCRIPT.csv
   â”‚  â”œâ”€ 302_openface_clnf.csv
   â”‚  â””â”€ ...
   â””â”€ ...



<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Tri‚ÄëModal Severity Fused Diagnosis ‚Äî Depression & PTSD</title>
  <meta name="description" content="Project page for 'Tri‚ÄëModal Severity Fused Diagnosis across Depression and Post‚Äëtraumatic Stress Disorders'." />
  <meta property="og:title" content="Tri‚ÄëModal Severity Fused Diagnosis ‚Äî Depression & PTSD" />
  <meta property="og:description" content="Tri‚Äëmodal fusion (text‚Äëaudio‚Äëface) for graded severity across depression (PHQ‚Äë8) and PTSD (PCL‚Äë5), with calibrated late fusion and clinician‚Äëoriented evaluation." />
  <meta property="og:type" content="website" />
  <meta name="theme-color" content="#f5f7fb" />
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;800&display=swap" rel="stylesheet">
  <style>
    :root{
      /* Light, advanced aesthetic */
      --bg:#f5f7fb;          /* page bg */
      --bg2:#ffffff;         /* panels */
      --ink:#0f172a;         /* primary text */
      --muted:#475569;       /* secondary text */
      --line:#e8edf4;        /* borders */
      --accent:#2563eb;      /* blue */
      --accent-2:#7c3aed;    /* violet */
      --accent-3:#06b6d4;    /* cyan */
      --radius:18px;
      --shadow:0 12px 36px rgba(15,23,42,.12);
      --max:1100px;
    }
    *,*::before,*::after{box-sizing:border-box}
    html,body{height:100%}
    body{margin:0;font-family:Inter,system-ui,Segoe UI,Roboto,Helvetica,Arial; background:
      radial-gradient(1100px 600px at 20% -10%, rgba(37,99,235,.09), transparent 70%),
      radial-gradient(1100px 600px at 80% -20%, rgba(124,58,237,.08), transparent 70%),
      var(--bg);
      color:var(--ink);
    }
    a{color:var(--accent); text-decoration:none}
    a:hover{text-decoration:underline}
    .container{max-width:var(--max); margin:0 auto; padding:0 20px}

    /* NAV */
    .nav{position:sticky; top:0; z-index:50; backdrop-filter:blur(10px); background:rgba(255,255,255,.75); border-bottom:1px solid var(--line)}
    .navwrap{display:flex; align-items:center; justify-content:space-between; height:70px}
    .brand{display:flex; gap:10px; align-items:center; font-weight:800; letter-spacing:.2px}
    .dot{width:10px;height:10px;border-radius:999px;background:linear-gradient(135deg,var(--accent),var(--accent-2)); box-shadow:0 0 0 6px rgba(37,99,235,.15)}
    .navlinks{display:flex; gap:20px}
    .navlinks a{color:var(--ink); font-weight:600}
    @media (max-width:820px){.navlinks{display:none}}

    /* HERO */
    .hero{padding:90px 0 40px; text-align:center}
    .title{font-size:clamp(34px,6vw,58px); font-weight:800; line-height:1.06; letter-spacing:-.02em; margin:0 auto; max-width:980px}
    .subtitle{font-size:clamp(16px,2.6vw,20px); color:var(--muted); margin-top:14px}
    .affil{color:#64748b; margin-top:6px}
    .cta{display:flex; flex-wrap:wrap; gap:12px; justify-content:center; margin-top:26px}
    .btn{display:inline-flex; align-items:center; gap:10px; padding:12px 16px; font-weight:600; border-radius:12px; background:var(--bg2); border:1px solid var(--line); box-shadow:var(--shadow)}
    .btn.primary{background:linear-gradient(135deg,#dbeafe,#ede9fe); border-color:#dbeafe}
    .btn svg{width:18px;height:18px}

    /* LAYOUT */
    section{padding:42px 0; scroll-margin-top:90px} /* avoids anchor overlap under sticky nav */
    .grid{display:grid; grid-template-columns:1fr 1fr; gap:22px; margin:26px auto; max-width:var(--max)}
    @media (max-width:980px){.grid{grid-template-columns:1fr}}
    .panel{background:var(--bg2); border:1px solid var(--line); border-radius:var(--radius); box-shadow:var(--shadow); padding:22px}

    /* FIGURES */
    .figure{background:#fbfdff; border:1px dashed #e5eaf2; border-radius:14px; display:flex; align-items:center; justify-content:center; min-height:320px}
    .figure img{max-width:100%; height:auto; border-radius:12px}
    .caption{color:#64748b; font-size:.95rem; margin-top:10px}
    .gallery{display:grid; grid-template-columns:repeat(auto-fit,minmax(260px,1fr)); gap:16px}
    figure{background:var(--bg2); border:1px solid var(--line); border-radius:14px; box-shadow:var(--shadow); margin:0; padding:12px}
    figcaption{font-size:.9rem; color:#475569; margin-top:8px}

    /* INFO CARDS */
    .two{display:grid; grid-template-columns:1fr 1fr; gap:18px}
    @media (max-width:920px){.two{grid-template-columns:1fr}}
    .cards{display:grid; grid-template-columns:repeat(auto-fit,minmax(240px,1fr)); gap:14px}
    .card{background:var(--bg2); border:1px solid var(--line); border-radius:14px; padding:16px; display:flex; gap:12px; align-items:center; justify-content:space-between; box-shadow:var(--shadow)}
    .badge{font-size:.8rem; color:#64748b}

    /* TABLES */
    table{width:100%; border-collapse:separate; border-spacing:0; background:var(--bg2); border:1px solid var(--line); border-radius:14px; overflow:hidden}
    th,td{padding:10px 12px; border-bottom:1px solid var(--line); text-align:left; font-size:.95rem}
    th{background:#f8fafc}
    tr:last-child td{border-bottom:none}

    /* BIBTEX */
    pre{background:#f8fafc; border:1px solid var(--line); padding:16px; border-radius:12px; overflow:auto}
    .copy{margin-left:8px; padding:8px 10px; border-radius:10px; background:#eef2ff; border:1px solid #e0e7ff; color:#1e3a8a; font-weight:600}
    .copy:hover{filter:brightness(1.05)}

    /* FOOTER */
    footer{border-top:1px solid var(--line); color:#475569; padding:30px 0 70px; text-align:center}
    .footlinks{display:flex; gap:14px; justify-content:center; flex-wrap:wrap}
    .mono{font-family: ui-monospace,SFMono-Regular,Menlo,Monaco,Consolas,\"Liberation Mono\",\"Courier New\",monospace}
  
    /* WALKTHROUGH (narrated figures) */
    .walk{display:grid; gap:22px}
    .step{display:grid; grid-template-columns:1.15fr 1fr; gap:20px; align-items:center}
    .step.reverse{grid-template-columns:1fr 1.15fr}
    @media (max-width:980px){.step,.step.reverse{grid-template-columns:1fr}}
    .step h3{margin:0 0 8px}
    .kicker{font-size:.78rem; text-transform:uppercase; letter-spacing:.12em; color:#64748b; font-weight:700}
    .pair{display:grid; grid-template-columns:1fr 1fr; gap:12px}
    @media (max-width:820px){.pair{grid-template-columns:1fr}}
    .figure img{object-fit:contain; background:#fff}
  </style>
</head>
<body>
  <nav class="nav">
    <div class="container navwrap">
      <div class="brand"><span class="dot"></span> <span>Tri‚ÄëModal Severity Fused Diagnosis</span></div>
      <div class="navlinks mono">
        <a href="#abstract">Abstract</a>
        <a href="#paper">Paper & Code</a>
        <a href="#figures">Figures</a>
        <a href="#results">Results</a>
        <a href="#manuscript">Full Manuscript</a>
        <a href="#bibtex">BibTeX</a>
      </div>
    </div>
  </nav>

  <header class="hero container">
    <h1 class="title">Tri‚ÄëModal Severity Fused Diagnosis across Depression and Post‚Äëtraumatic Stress Disorders</h1>
    <p class="subtitle">Manuscript submitted to <strong>IEEE Transactions on Affective Computing</strong> ¬∑ 2025</p>
    <p class="affil">Filippo Cenacchi ¬∑ Deborah Richards ¬∑ Longbing Cao ‚Äî Macquarie University</p>
    <div class="cta">
      <a class="btn primary" href="https://arxiv.org/abs/2510.20239" target="_blank" rel="noopener">üìÑ Paper (arXiv)</a>
      <a class="btn" href="https://github.com/cenacchi2000/EDAI-Trimodal" target="_blank" rel="noopener">üíª Code</a>
      <a class="btn" href="#figures" title="Scroll to figures">üñºÔ∏è Figures</a>
    </div>
  </header>

  <div class="container grid">
    <div class="panel">
      <div class="figure">
        <!-- Overleaf: \includegraphics{Diagram} -->
        <img src="assets/Diagram.png" alt="Architecture overview: text(768) + audio(256) + face(512) ‚Üí standardized late fusion (1536‚ÄëD) with calibrated XGBoost heads for PHQ‚Äë8 and PTSD"/>
      </div>
      <div class="caption">Fig. ‚Äî Architecture overview (Overleaf file: <code>Diagram.png</code>; use .svg/.png export from your vector source).</div>
    </div>
    <div class="panel">
      <h2 style="margin-top:0">Key Outcomes (cross‚Äëvalidated)</h2>
      <ul>
        <li><strong>Severity‚Äëaware</strong> multi‚Äëdisorder prediction (PHQ‚Äë8 5‚Äëway; PTSD 3‚Äëway).</li>
        <li><strong>Fusion robustness</strong> vs. unimodal baselines; higher decision‚Äëcurve net benefit.</li>
        <li><strong>Interpretability</strong> via SHAP: text dominates depression, audio/face strengthen PTSD.</li>
      </ul>
      <p class="caption">Drop your exported figures into <code>assets/</code> with the exact Overleaf names below; no dark background; margins tuned to avoid overlap with sticky nav.</p>
    </div>
  </div>

  <section id="abstract" class="container">
    <h2>Abstract</h2>
    <p>
      Depression and PTSD frequently co‚Äëoccur, making automated assessment difficult when framed as binary, disorder‚Äëspecific tasks. We present a unified tri‚Äëmodal severity framework that synchronizes sentence‚Äëlevel transformer text embeddings, log‚ÄëMel audio statistics with deltas, and OpenFace‚Äëbased facial action units, gaze, and head‚Äëpose descriptors. A calibrated late‚Äëfusion classifier outputs graded severities for depression (PHQ‚Äë8; five classes) and PTSD (three classes). On DAIC‚Äëderived corpora, fusion matches the strongest unimodal baseline on accuracy and weighted‚ÄëF1 while improving decision‚Äëcurve utility and robustness to missing or noisy modalities. Errors concentrate between adjacent severity levels; extremes are reliably identified. SHAP attributions align with clinical markers: linguistic cues dominate depression; audio‚Äìfacial cues are critical for PTSD.
    </p>
  </section>

  <section id="paper" class="container">
    <h2>Paper & Resources</h2>
    <div class="cards">
      <a class="card" href="https://arxiv.org/abs/2510.20239" target="_blank" rel="noopener">
        <div>
          <div><strong>Paper (arXiv)</strong></div>
          <div class="badge">v1 ¬∑ 2510.20239</div>
        </div>
        <span>‚Üó</span>
      </a>
      <a class="card" href="https://github.com/cenacchi2000/EDAI-Trimodal" target="_blank" rel="noopener">
        <div>
          <div><strong>Code</strong></div>
          <div class="badge">GitHub repository</div>
        </div>
        <span>‚Üó</span>
      </a>
      <a class="card" href="#figures" rel="noopener">
        <div>
          <div><strong>Full Figure Gallery</strong></div>
          <div class="badge">Overleaf file names</div>
        </div>
        <span>‚Üì</span>
      </a>
    </div>
  </section>

  <section class="container two">
    <div class="panel">
      <h2>Feature Extractors</h2>
      <p><strong>Text</strong>: sentence‚Äëtransformers/all‚Äëmpnet‚Äëbase‚Äëv2; sentence mean‚Äëpooling ‚Üí 768‚ÄëD participant embedding.</p>
      <p><strong>Audio</strong>: 16 kHz log‚ÄëMel spectrograms (64 bins; 25 ms window; 10 ms hop) with Œî; per‚Äëbin mean/std ‚Üí 256‚ÄëD.</p>
      <p><strong>Face</strong>: OpenFace 2.0 AUs, gaze, head‚Äëpose; statistical + derivative measures ‚Üí 512‚ÄëD.</p>
    </div>
    <div class="panel">
      <h2>Fusion & Training</h2>
      <p>Standardize each modality within folds; concatenate to 1,536‚ÄëD and train disorder‚Äëspecific XGBoost heads (multi:softprob) with inverse‚Äëfrequency class weights; stratified 5‚Äëfold CV with seed‚Äëensembles; export out‚Äëof‚Äëfold predictions for metrics and plots.</p>
    </div>
  </section>

  <section id="figures" class="container">
    <h2>Results in Pictures ‚Äî a narrated walkthrough</h2>
    <div class="walk">

      <div class="panel step">
        <figure class="figure">
          <img data-required="logmel.png" src="assets/logmel.png" alt="Representative log‚ÄëMel spectrogram" loading="lazy" decoding="async"/>
        </figure>
        <div class="text">
          <div class="kicker">Modality: Audio</div>
          <h3>Speech energy and rhythm (Fig. ‚Äî <code>logmel.png</code>)</h3>
          <p>Bright vertical stripes mark voiced segments; darker gaps are low‚Äëenergy pauses. Our audio embedding summarizes each Mel bin‚Äôs mean/variance and <em>Œî</em>, preserving prosody and arousal cues that are especially informative for PTSD.</p>
        </div>
      </div>

      <div class="panel step reverse">
        <div class="text">
          <div class="kicker">Per‚Äëclass behavior</div>
          <h3>Extremes are easier than middles (PHQ‚Äë8)</h3>
          <p>The bar plot shows weighted F1 by class: <em>minimal</em> and <em>severe</em> dominate, while confusion concentrates between adjacent tiers (mild‚Üîmoderate, moderate‚Üîmod. severe). This reflects clinical ambiguity in the mid‚Äëranges.</p>
        </div>
        <figure class="figure">
          <img data-required="perclass_f1_XGB_DEP_ALL.png" src="assets/perclass_f1_XGB_DEP_ALL.png" alt="Per‚Äëclass F1 ‚Äî Depression fusion" loading="lazy" decoding="async"/>
        </figure>
      </div>

      <div class="panel step">
        <figure class="figure">
          <img data-required="perclass_f1_XGB_PTSD_ALL.png" src="assets/perclass_f1_XGB_PTSD_ALL.png" alt="Per‚Äëclass F1 ‚Äî PTSD fusion" loading="lazy" decoding="async"/>
        </figure>
        <div class="text">
          <div class="kicker">Per‚Äëclass behavior</div>
          <h3>PTSD shows sharp separation at the severe end</h3>
          <p>For PTSD, the <em>severe</em> class is cleanly identified, while the none/mild vs. moderate boundary remains softer ‚Äî consistent with overlapping symptomatology.</p>
        </div>
      </div>

      <div class="panel step reverse">
        <div class="text">
          <div class="kicker">Where errors happen</div>
          <h3>Confusion matrices: adjacent tiers dominate errors</h3>
          <p>Both disorders show diagonal concentration with off‚Äëdiagonal spill between neighboring severities ‚Äî evidence that the model respects the ordinal structure.</p>
        </div>
        <div class="pair">
          <figure class="figure">
            <img data-required="pooled_cm_XGB_DEP_ALL.png" src="assets/pooled_cm_XGB_DEP_ALL.png" alt="Confusion matrix ‚Äî Depression fusion" loading="lazy" decoding="async"/>
          </figure>
          <figure class="figure">
            <img data-required="pooled_cm_XGB_PTSD_ALL.png" src="assets/pooled_cm_XGB_PTSD_ALL.png" alt="Confusion matrix ‚Äî PTSD fusion" loading="lazy" decoding="async"/>
          </figure>
        </div>
      </div>

      <div class="panel step">
        <figure class="pair">
          <img data-required="dep_bars_fixed_v12.png" src="assets/dep_bars_fixed_v12.png" alt="Modality contributions ‚Äî Depression" loading="lazy" decoding="async"/>
          <img data-required="ptsd_bars_fixed_v12.png" src="assets/ptsd_bars_fixed_v12.png" alt="Modality contributions ‚Äî PTSD" loading="lazy" decoding="async"/>
        </figure>
        <div class="text">
          <div class="kicker">What each stream adds</div>
          <h3>Fusion equals best unimodal ‚Äî and is more robust</h3>
          <p>Text leads depression, while audio+face contribute more to PTSD. The tri‚Äëmodal model matches text on headline ACC/F1 yet yields higher decision‚Äëcurve utility and graceful degradation under missing streams.</p>
        </div>
      </div>

      <div class="panel step reverse">
        <div class="text">
          <div class="kicker">Operating characteristics</div>
          <h3>High AUC; PR confirms screening utility</h3>
          <p>ROC curves approach ceiling, while PR curves show strong recall at high precision ‚Äî useful when screening severe cases where false negatives are costly.</p>
        </div>
        <figure class="pair">
          <img data-required="pr_XGB_DEP_ALL.png" src="assets/pr_XGB_DEP_ALL.png" alt="PR ‚Äî Depression" loading="lazy" decoding="async"/>
          <img data-required="pr_XGB_PTSD_ALL.png" src="assets/pr_XGB_PTSD_ALL.png" alt="PR ‚Äî PTSD" loading="lazy" decoding="async"/>
        </figure>
      </div>

      <div class="panel step">
        <figure class="pair">
          <img data-required="pca2d_DEP_ALL.png" src="assets/pca2d_DEP_ALL.png" alt="PCA ‚Äî Depression" loading="lazy" decoding="async"/>
          <img data-required="tsne2d_DEP_ALL.png" src="assets/tsne2d_DEP_ALL.png" alt="t‚ÄëSNE ‚Äî Depression" loading="lazy" decoding="async"/>
        </figure>
        <div class="text">
          <div class="kicker">Latent space</div>
          <h3>Fused embeddings carve clinical structure</h3>
          <p>t‚ÄëSNE reveals clearer clustering than PCA, especially for severe categories. Overlap persists in middle severities ‚Äî mirroring confusion matrices.</p>
        </div>
      </div>

      <div class="panel step reverse">
        <div class="text">
          <div class="kicker">Decision support</div>
          <h3>Decision‚Äëcurve analysis favors fusion</h3>
          <p>Across a wide threshold range, net benefit exceeds ‚Äútreat‚Äëall/none‚Äù and unimodals ‚Äî supporting threshold‚Äëbased triage and stepped care.</p>
        </div>
        <figure class="pair">
          <img data-required="decision_curve_DEP_fusion_xgb_perclass.png" src="assets/decision_curve_DEP_fusion_xgb_perclass.png" alt="Decision curve ‚Äî Depression" loading="lazy" decoding="async"/>
          <img data-required="decision_curve_PTSD_fusion_xgb_perclass.png" src="assets/decision_curve_PTSD_fusion_xgb_perclass.png" alt="Decision curve ‚Äî PTSD" loading="lazy" decoding="async"/>
        </figure>
      </div>

      <div class="panel step">
        <figure class="pair">
          <img data-required="shap_DEP_fusion_xgb.png" src="assets/shap_DEP_fusion_xgb.png" alt="SHAP ‚Äî Depression" loading="lazy" decoding="async"/>
          <img data-required="shap_PTSD_fusion_xgb.png" src="assets/shap_PTSD_fusion_xgb.png" alt="SHAP ‚Äî PTSD" loading="lazy" decoding="async"/>
        </figure>
        <div class="text">
          <div class="kicker">Interpretability</div>
          <h3>What the model learns</h3>
          <p>Language features (affect, pronouns, coherence) drive depression; prosodic arousal and facial expressivity weigh heavier for PTSD. This aligns with clinical theory and aids trust calibration.</p>
        </div>
      </div>

    </div>
  </section>

  <section id="results" class="container">
    <h2>Selected Results</h2>
    <div class="two">
      <div class="panel">
        <h3>Label Distributions</h3>
        <table>
          <thead><tr><th>Depression (PHQ‚Äë8)</th><th>n</th><th>PTSD (PCL‚Äë5 bands)</th><th>n</th></tr></thead>
          <tbody>
            <tr><td>Minimal (0‚Äì4)</td><td>187</td><td>None/Mild (‚â§20)</td><td>85</td></tr>
            <tr><td>Mild (5‚Äì9)</td><td>96</td><td>Moderate (21‚Äì40)</td><td>180</td></tr>
            <tr><td>Moderate (10‚Äì14)</td><td>64</td><td>Severe (‚â•41)</td><td>140</td></tr>
            <tr><td>Moderately severe (15‚Äì19)</td><td>43</td><td></td><td></td></tr>
            <tr><td>Severe (20‚Äì24)</td><td>15</td><td></td><td></td></tr>
          </tbody>
        </table>
      </div>
      <div class="panel">
        <h3>Setup (fixed across folds)</h3>
        <p>Text 768‚ÄëD ¬∑ Audio 256‚ÄëD ¬∑ Face 512‚ÄëD ‚Üí Fusion 1,536‚ÄëD. XGBoost multi:softprob; 2k trees; lr=0.05; depth=8; subsample=0.9; colsample=0.8; Œª=2. Stratified 5‚Äëfold CV with inverse class weights. Metrics include ACC, weighted‚ÄëF1, AUC, MCC, Œ∫, PR/ROC, decision‚Äëcurves.</p>
      </div>
    </div>

    <div class="panel" style="margin-top:16px">
      <h3>Cross‚Äëvalidated Performance (excerpt)</h3>
      <table>
        <thead><tr><th>Task</th><th>Model</th><th>ACC</th><th>F1w</th><th>AUC</th></tr></thead>
        <tbody>
          <tr><td>Depression</td><td>TEXT (XGB)</td><td>0.862</td><td>0.860</td><td>0.964</td></tr>
          <tr><td>Depression</td><td>Fusion ALL (XGB)</td><td>0.852</td><td>0.850</td><td>0.961</td></tr>
          <tr><td>PTSD</td><td>TEXT (XGB)</td><td>0.862</td><td>0.861</td><td>0.971</td></tr>
          <tr><td>PTSD</td><td>Fusion ALL (XGB)</td><td>0.854</td><td>0.854</td><td>0.970</td></tr>
        </tbody>
      </table>
      <p class="caption">Full Table III with confidence intervals can be provided as CSV or expandable table.</p>
    </div>
  </section>

  <section id="manuscript" class="container">
    <h2>Full Manuscript</h2>
    <div class="panel">
      <p class="caption">For 1:1, word‚Äëfor‚Äëword viewing, drop your PDF at <code>assets/paper.pdf</code> or change the <code>src</code> below to the arXiv PDF. This avoids copy‚Äëpasting the entire LaTeX into HTML.</p>
      <div class="figure" style="min-height:0;padding:0;border-style:solid">
        <iframe src="https://arxiv.org/pdf/2510.20239.pdf#view=FitH" width="100%" height="720" style="border:0" referrerpolicy="no-referrer" loading="lazy" title="arXiv PDF"></iframe>
        <p class="caption">If you prefer to host locally, place your compiled PDF at <code>assets/paper.pdf</code> and replace the <code>iframe</code> <code>src</code> with <code>assets/paper.pdf#view=FitH</code>. On GitHub Pages, PDFs sometimes fail to load if the file is missing or the repo hasn‚Äôt served it yet.</p>
      </div>
    </div>
  </section>

  <section id="bibtex" class="container">
    <h2 style="display:flex;align-items:center;gap:8px">BibTeX <button class="copy mono" id="copyBib">Copy</button></h2>
    <pre class="mono" id="bib">
@article{Cenacchi2025TriModal,
  title   = {Tri-Modal Severity Fused Diagnosis across Depression and Post-traumatic Stress Disorders},
  author  = {Cenacchi, Filippo and Richards, Deborah and Cao, Longbing},
  journal = {IEEE Transactions on Affective Computing},
  year    = {2025},
  note    = {arXiv:2510.20239},
  url     = {https://arxiv.org/abs/2510.20239}
}
    </pre>
  </section>

  <footer>
    <div class="container">
      <div class="footlinks"><span>¬© 2025 Filippo Cenacchi</span> <span>¬∑</span> <a href="mailto:filippo.cenacchi@mq.edu.au">Contact</a> <span>¬∑</span> <a href="https://github.com/cenacchi2000/EDAI-Trimodal" target="_blank">Code</a></div>
      <div style="margin-top:10px">Static, single‚Äëfile site. Drop images in <code>assets/</code> and push to GitHub Pages.</div>
    </div>
  </footer>

  <script>
    // Copy BibTeX
    document.getElementById('copyBib').addEventListener('click', async () => {
      const txt = document.getElementById('bib').innerText.trim();
      try{ await navigator.clipboard.writeText(txt); const b = document.getElementById('copyBib'); b.textContent = 'Copied ‚úì'; setTimeout(()=> b.textContent='Copy', 1500);}catch{ alert('Copy failed ‚Äî select and copy manually.'); }
    });
  </script>
  <script>
    // Graceful handling for missing images ‚Äî show a hint instead of a broken icon
    document.querySelectorAll('img[data-required]').forEach(img=>{
      img.addEventListener('error',()=>{
        const name = img.getAttribute('data-required');
        const note = document.createElement('div');
        note.className = 'caption';
        note.textContent = `Missing asset: assets/${name} ‚Äî add this file to render this panel.`;
        const holder = img.closest('figure,.panel,.figure');
        if(holder){ holder.appendChild(note); }
        img.remove();
      }, {once:true});
    });
  </script>
</body>
</html>

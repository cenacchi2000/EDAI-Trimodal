<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Tri-Modal Severity Fused Diagnosis across Depression & PTSD</title>
  <meta name="description" content="Tri-modal, severity-aware diagnosis for depression (PHQ-8) and PTSD using text, audio, and facial signals with calibrated late fusion.">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800;900&display=swap" rel="stylesheet">
  <style>
    :root{
      --bg:#f7f9fc;
      --bg-grad-from:#f7fbff;
      --bg-grad-to:#eef3ff;
      --ink:#0b1727;
      --muted:#5b6b80;
      --brand:#2250f4;
      --brand-ink:#0f2ea3;
      --card:#ffffff;
      --ring:rgba(34,80,244,.15);
      --shadow:0 10px 30px rgba(15, 36, 65, .08);
      --radius:18px;
      --radius-lg:22px;
      --radius-xl:28px;
      --gap:22px;
      --gap-lg:28px;
      --max:1200px;
    }
    *{box-sizing:border-box}
    html,body{height:100%}
    body{
      margin:0;
      font-family:Inter,system-ui,-apple-system,Segoe UI,Roboto,"Helvetica Neue",Arial;
      color:var(--ink);
      background:
        radial-gradient(1200px 600px at 20% -10%, var(--bg-grad-from), transparent 60%),
        radial-gradient(1200px 600px at 80% -10%, var(--bg-grad-to), transparent 60%),
        var(--bg);
      line-height:1.55;
      -webkit-font-smoothing:antialiased;
      -moz-osx-font-smoothing:grayscale;
    }
    /* ===== MemFlow-like display titles ===== */
:root{
  --title-weight: 900;
  --title-tracking: -0.02em;
}

.title{
  font-weight: var(--title-weight);
  letter-spacing: var(--title-tracking);
  font-size: clamp(38px, 6vw, 60px);
  line-height: 1.05;
  text-align: center;
}

.section-title{
  font-weight: var(--title-weight);
  letter-spacing: var(--title-tracking);
  font-size: clamp(28px, 4vw, 40px);
  line-height: 1.08;
  text-align: center;
  margin: 0 0 20px;
  position: relative;
}

.section-title::after{
  content:"";
  display:block;
  width:72px;
  height:3px;
  border-radius:3px;
  margin:14px auto 0;
  background: linear-gradient(90deg, rgba(34,80,244,.5), rgba(34,80,244,.15));
}

  /* --- Abstract typography --- */
.section#abstract h2{
  font-size: clamp(2.2rem, 2.2vw + 1.4rem, 3.2rem);
  letter-spacing:-0.02em;
}

.section#abstract p{
  max-width: 75ch;
  margin-inline:auto;
  font-size: clamp(1.1rem, 0.9vw + 1rem, 1.45rem);
  line-height: 1.9;
  text-align: justify;
  text-justify: inter-word;
  hyphens: auto;
  color: var(--muted, #5b6b80);
}
/* --- Results KPIs / badges / animations --- */
.kpis{display:grid;grid-template-columns:repeat(12,1fr);gap:var(--gap)}
.kpi{grid-column:span 3;background:var(--card);border:1px solid rgba(15,36,65,.06);
  border-radius:var(--radius);box-shadow:var(--shadow);padding:16px 18px}
.kpi h4{margin:2px 0 8px;font-size:14px;color:var(--muted);font-weight:700;letter-spacing:.04em}
.kpi .big{font-weight:900;font-size:36px;letter-spacing:-.02em}
.kpi small{color:var(--muted)}
@media(max-width:900px){.kpi{grid-column:span 6}}
@media(max-width:640px){.kpi{grid-column:1/-1}}

.badges{display:flex;flex-wrap:wrap;gap:8px;margin:8px 0 0}
.badge{border:1px solid rgba(15,36,65,.10);background:#fff;border-radius:999px;padding:6px 10px;font-weight:600;font-size:12px}
.badge.brand{background:rgba(34,80,244,.08);border-color:rgba(34,80,244,.15);color:var(--brand-ink)}

.accordion{border:1px solid rgba(15,36,65,.08);border-radius:var(--radius);background:#fff;box-shadow:var(--shadow)}
.accordion summary{cursor:pointer;list-style:none;padding:14px 16px;font-weight:800}
.accordion summary::-webkit-details-marker{display:none}
.accordion .content{padding:0 16px 16px;color:var(--muted)}
.accordion .cols{display:grid;grid-template-columns:1fr 1fr;gap:12px}
@media(max-width:760px){.accordion .cols{grid-template-columns:1fr}}

.reasons{display:grid;gap:12px;margin-top:14px}
.reason{background:#fff;border:1px solid rgba(15,36,65,.08);border-radius:14px;padding:12px}

.fade-in{opacity:0;transform:translateY(8px);transition:opacity .6s ease,transform .6s ease}
.fade-in.show{opacity:1;transform:none}
.count{transition:opacity .3s ease}

/* Optional: slightly larger subsection headings inside cards */
.card h3{
  font-weight: 800;
  letter-spacing: -0.01em;
}

    /* ===== Top nav (blurred, light) ===== */
    .nav {
      position:sticky; top:0; z-index:30;
      backdrop-filter: saturate(1.2) blur(8px);
      background:rgba(255,255,255,.72);
      border-bottom:1px solid rgba(15,36,65,.06);
    }
    .nav-inner{max-width:var(--max); margin:auto; display:flex; gap:14px; align-items:center; padding:10px 20px}
    .brand{font-weight:700; letter-spacing:.02em; color:var(--ink)}
    .nav-spacer{flex:1}
    .chip{
      appearance:none; border:1px solid rgba(15,36,65,.08);
      background:#fff; color:var(--ink); border-radius:999px;
      padding:9px 14px; font-weight:600; font-size:14px;
      transition: all .2s ease; text-decoration:none; display:inline-flex; align-items:center; gap:8px;
      box-shadow:0 1px 0 rgba(0,0,0,.03);
    }
    .chip:hover{border-color:rgba(34,80,244,.35); box-shadow:0 6px 18px rgba(34,80,244,.12); transform:translateY(-1px)}
    .chip.primary{background:var(--brand); color:#fff; border-color:transparent}
    .chip.primary:hover{background:#1f46d9}

    /* ===== Hero ===== */
    .hero{position:relative; padding:64px 20px 16px}
    .hero::before{
      content:""; position:absolute; inset:-20vh 0 auto 0; height:60vh; pointer-events:none;
      background: radial-gradient(800px 320px at 50% -10%, rgba(34,80,244,.08), transparent 70%);
      z-index:0; opacity:.8;
    }
    .hero-inner{max-width:var(--max); margin:0 auto; position:relative; z-index:1}
    .title{
      font-weight:900; letter-spacing:-.02em; line-height:1.06;
      font-size: clamp(34px, 5vw, 54px);
      text-align:center; margin:6px 0 10px;
    }
    .subtitle{
      text-align:center; color:var(--muted); font-weight:600; margin-bottom:22px;
    }
    .authors{ text-align:center; color:var(--muted); font-weight:500; }
    .authors a{color:var(--brand); text-decoration:none}
    .authors a:hover{color:var(--brand-ink); text-decoration:underline}
    .cta-row{display:flex; gap:12px; justify-content:center; margin:26px 0 34px}
    .cta-row .chip{padding:11px 16px; font-weight:700}


    /* === Pill buttons (exact look like the screenshot) === */
.pill-row{
  display:flex; gap:18px; justify-content:center; align-items:center;
  margin:18px 0 36px; flex-wrap:wrap;
}
.pill{
  appearance:none; border:0; border-radius:999px;
  padding:14px 22px;
  background:#1f2937; color:#fff;
  font-weight:700; font-size:18px;
  display:inline-flex; gap:12px; align-items:center;
  text-decoration:none;
  box-shadow:0 4px 14px rgba(15,23,42,.18);
  transition:transform .12s ease, box-shadow .12s ease, background .12s ease;
}
.pill:hover{ transform:translateY(-1px); box-shadow:0 8px 22px rgba(15,23,42,.18); background:#111827; }
.pill:focus-visible{ outline:0; box-shadow:0 0 0 4px rgba(59,130,246,.28); }
.pill svg{ width:22px; height:22px; flex:0 0 22px; color:#d8dee8; }

    .pdf-placeholder{
  display:flex; align-items:center; gap:14px; padding:16px 18px;
  border:1px dashed rgba(34,80,244,.35);
  background:rgba(34,80,244,.04);
  border-radius:14px; margin-top:8px;
}

    /* ===== Architecture hero image (centered, frameless) ===== */
    .arch-wrap{display:flex; justify-content:center}
    .arch{
      width:min(1100px, 92vw);
      border-radius:20px;
      box-shadow: var(--shadow);
      background:#fff;
      padding:0; overflow:hidden; /* no frame */
    }
    .arch img{ display:block; width:100%; height:auto; object-fit:contain }

    /* --- Card grid tightening & centering --- */
.cards{
  display:grid;
  grid-template-columns: repeat(auto-fit, minmax(320px,1fr));
  gap: 28px;
}

.card{
  background: #fff;
  border-radius: 18px;
  box-shadow: 0 10px 30px rgba(15,23,42,.06);
  padding: 18px;
  transition: transform .25s ease, box-shadow .25s ease, filter .25s ease;
  will-change: transform;
}

/* remove “fixed height”/extra space if you had it */
.card .media,
.card .media > img{
  height: auto !important;
  max-height: none !important;
}

.card .media{
  margin: 8px 0 14px;
}

.card .media > img{
  display:block;
  margin-inline:auto;
  max-width: 100%;
  object-fit: contain;
}

.card .body{
  margin-top: 8px;
}

.card:hover{
  transform: translateY(-2px);
  box-shadow: 0 16px 40px rgba(15,23,42,.10);
}

/* --- 3D flip + fullscreen on hover --- */
.card-3d{
  perspective: 1600px;
  position: relative;
}

.card-3d .card-inner{
  position: relative;
  transform-style: preserve-3d;
  transition: transform .6s cubic-bezier(.2,.7,.2,1);
  min-height: 280px;
}

.card-3d .card-face{
  position: relative;
  backface-visibility: hidden;
  transform: translateZ(0);
}

/* back face hidden until hovered */
.card-3d .card-back{
  position: absolute;
  inset: 0;
  border-radius: 18px;
  background: #fff;
  transform: rotateY(180deg);
  overflow: hidden;
}

/* flip to back when hovered */
.card-3d:hover .card-inner{
  transform: rotateY(180deg);
}

/* fullscreen center + page blur using :has() */
.cards{
  position: relative;
}

.cards:has(.card-3d:hover) .card-3d:not(:hover){
  filter: blur(4px) saturate(.8);
  pointer-events: none;
}

.card-3d:hover{
  position: fixed;
  inset: auto;
  top: 50%;
  left: 50%;
  transform: translate(-50%,-50%) !important;
  z-index: 9999;
  width: min(1100px, 92vw);
  height: min(82vh, 920px);
  padding: 0;                /* tighten */
  box-shadow: 0 30px 120px rgba(2,8,23,.35);
}

/* ensure the inner fills the fullscreen card */
.card-3d:hover .card-inner,
.card-3d:hover .card-back{
  height: 100%;
}

/* back layout: figure + long text side-by-side */
.back-wrap{
  display: grid;
  grid-template-columns: 1.2fr 1fr;
  gap: 22px;
  height: 100%;
  padding: 24px;
}

.back-figure{
  display:flex;
  align-items:center;
  justify-content:center;
  overflow:hidden;
  border-radius: 14px;
  background: linear-gradient(180deg,#f8fbff,#eef3ff);
}

.back-figure img{
  width: 100%;
  max-height: 100%;
  object-fit: contain;
}

.back-text{
  overflow:auto;
  padding-right: 6px;
}

.back-text h4{
  margin: 0 0 8px;
  font-size: clamp(1.1rem, .6vw + 1rem, 1.4rem);
}
.back-text p{
  font-size: clamp(1rem, .45vw + .95rem, 1.15rem);
  line-height: 1.75;
  color: var(--muted, #5b6b80);
}

/* smoothness + accessibility */
@media (prefers-reduced-motion: reduce){
  .card-3d .card-inner{ transition: none; }
  .card{ transition: none; }
}

    /* Tables */
    .table{width:100%; border-collapse: collapse; overflow:hidden; border-radius:14px; background:#fff; box-shadow:var(--shadow)}
    .table th, .table td{ padding:12px 14px; border-bottom:1px solid rgba(15,36,65,.06); text-align:left; font-size:14.5px }
    .table thead th{ background:#f6f8ff; color:#1d2b4a; font-weight:700 }
    .table tr:last-child td{ border-bottom:none }

    /* Lightbox (no page-darkening) */
    .lightbox{ position:fixed; inset:0; display:none; align-items:center; justify-content:center;
      background:rgba(255,255,255,.8); /* light, not dark */
      backdrop-filter: blur(8px) saturate(1.2); z-index:50; padding:24px;
    }
    .lightbox.open{display:flex}
    .lightbox img{max-width:92vw; max-height:88vh; border-radius:16px; box-shadow:0 30px 80px rgba(0,0,0,.15)}
    .lightbox .close{position:absolute; top:16px; right:16px; background:#fff; border:1px solid rgba(15,36,65,.12); border-radius:999px; padding:8px 12px; font-weight:700; cursor:pointer}

    /* Footer */
    footer{padding:40px 20px 80px; color:var(--muted)}
    footer .container{display:flex; justify-content:space-between; gap:16px; flex-wrap:wrap}
    a.inline{color:var(--brand); text-decoration:none}
    a.inline:hover{text-decoration:underline}

    /* Smooth scroll */
    html{scroll-behavior:smooth}
  </style>
</head>
<body>

  <!-- ===== NAV ===== -->
  <nav class="nav">
    <div class="nav-inner">
      <div class="brand">Tri-Modal Severity Fused Diagnosis</div>
      <div class="nav-spacer"></div>
      <a class="chip" href="#abstract">Abstract</a>
      <a class="chip" href="#figures">Figures</a>
      <a class="chip" href="#results">Results</a>
      <a class="chip" href="#manuscript">Paper</a>
      <a class="chip" href="https://github.com/cenacchi2000/EDAI-Trimodal" target="_blank" rel="noopener">Code</a>
    </div>
  </nav>

  <!-- ===== HERO ===== -->
  <header class="hero" id="top">
    <div class="hero-inner">
      <h1 class="title">Tri-Modal Severity Fused Diagnosis across<br/>Depression &amp; PTSD</h1>

      <div class="authors">
  <div class="names">
    <a href="https://cenacchi2000.github.io/filippocenacchi.github.io/" target="_blank" rel="noopener">Filippo Cenacchi</a> ·
    <a href="https://scholar.google.com.au/citations?user=p0BxAfAAAAAJ&hl=en" target="_blank" rel="noopener">Deborah Richards</a> ·
    <a href="https://scholar.google.com.au/citations?user=cDs3DM8AAAAJ&hl=en" target="_blank" rel="noopener">Longbing Cao</a>
  </div>
  <div class="affil">Macquarie University</div>
</div>


     <div class="pill-row">
  <!-- Paper -->
  <a class="pill" href="#manuscript" aria-label="Open paper section">
    <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.7" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true">
      <path d="M12 20h9"/><path d="M16.5 3.5a2.12 2.12 0 0 1 3 3L7 19l-4 1 1-4L16.5 3.5z"/>
    </svg>
    <span>Paper</span>
  </a>

  <!-- Code -->
  <a class="pill" href="https://github.com/cenacchi2000/EDAI-Trimodal" target="_blank" rel="noopener" aria-label="Open code repository">
    <svg viewBox="0 0 24 24" fill="currentColor" aria-hidden="true">
      <path d="M12 .5a11.5 11.5 0 0 0-3.64 22.41c.57.1.78-.25.78-.55v-2.1c-3.18.69-3.85-1.37-3.85-1.37-.52-1.32-1.27-1.67-1.27-1.67-1.04-.71.08-.69.08-.69 1.15.08 1.76 1.18 1.76 1.18 1.02 1.75 2.68 1.24 3.33.95.1-.76.4-1.24.72-1.53-2.54-.29-5.22-1.27-5.22-5.65 0-1.25.45-2.28 1.18-3.08-.12-.29-.51-1.46.11-3.04 0 0 .96-.31 3.15 1.18a10.9 10.9 0 0 1 5.73 0c2.19-1.49 3.15-1.18 3.15-1.18.62 1.58.23 2.75.11 3.04.73.8 1.18 1.83 1.18 3.08 0 4.39-2.69 5.35-5.25 5.64.41.36.77 1.07.77 2.16v3.2c0 .3.21.66.79.55A11.5 11.5 0 0 0 12 .5z"/>
    </svg>
    <span>Code</span>
  </a>

  <!-- Figures -->
  <a class="pill" href="#figures" aria-label="Jump to figures">
    <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.7" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true">
      <rect x="3" y="4" width="18" height="14" rx="2" ry="2"></rect>
      <circle cx="8.5" cy="9.5" r="1.5"></circle>
      <path d="M21 16l-5.5-5.5L9 17l-3-3-3 3"></path>
    </svg>
    <span>Figures</span>
  </a>
</div>


      <!-- Architecture image, centered, no frame -->
      <div class="arch-wrap">
        <figure class="arch">
          <!-- Replace 'assets/Diagram.png' with your exported diagram. SVG/PNG recommended. -->
          <img src="assets/Diagram.png" alt="Architecture overview: text 768-D, audio 256-D, face 512-D fused to 1,536-D with calibrated late fusion." id="arch-img">
        </figure>
      </div>
    </div>
  </header>

  <!-- ===== ABSTRACT ===== -->
  <section id="abstract" class="section">
    <div class="container">
      <h2 class="section-title">Abstract</h2>
      <p class="lead">
        Depression and PTSD frequently co-occur, complicating automated assessment when framed as binary, disorder-specific tasks.
        We present a unified tri-modal severity framework that synchronizes sentence-level transformer text embeddings, log-Mel
        audio statistics with deltas, and OpenFace-based facial action units, gaze, and head-pose descriptors to output graded
        severities for depression (PHQ-8; five classes) and PTSD (three classes). A calibrated late-fusion classifier produces
        disorder-specific probabilities that support decision-curve analysis and robustness to missing/noisy modalities. Errors
        concentrate between adjacent severities; extremes are reliably identified. SHAP attributions align with clinical markers:
        linguistic cues dominate depression, audio–facial cues strengthen PTSD.
      </p>
    </div>
  </section>

  <!-- ===== FIGURE WALKTHROUGH (narrated; filenames match Overleaf) ===== -->
  <section id="figures">
    <div class="container">
      <h2 class="section-title">Figure Walkthrough</h2>


<div class="cards">

  <!-- 1) Signal: log-Mel spectrogram -->
  <div class="card card-3d">
    <div class="card-inner">
      <div class="card-face card-front">
        <div class="media">
          <img src="assets/logmel.png" alt="Representative log-Mel spectrogram">
        </div>
        <h3>Signal view — Audio (Mel)</h3>
        <p class="muted">Vertical bands = voiced speech; troughs = pauses and low energy.</p>
      </div>
      <div class="card-face card-back">
        <div class="back-wrap">
          <div class="back-figure"><img src="assets/logmel.png" alt="log-Mel spectrogram (large)"></div>
          <div class="back-text">
            <h4>What this shows</h4>
            <p>We summarize speech into time–frequency statistics (means/SDs over Mel bins and Δ)
               that capture tempo, spectral slope, and stability—signals linked to affect and arousal.
               This compact 256-D audio embedding complements text and facial cues in fusion.</p>
          </div>
        </div>
      </div>
    </div>
  </div>

  <!-- 2) Modality roles — Depression -->
  <div class="card card-3d">
    <div class="card-inner">
      <div class="card-face card-front">
        <div class="media"><img src="assets/dep_bars_fixed_v12.png" alt="Modality contributions in Depression"></div>
        <h3>Modality roles — Depression</h3>
        <p class="muted">Text separates severities; audio/face stabilize near boundaries.</p>
      </div>
      <div class="card-face card-back">
        <div class="back-wrap">
          <div class="back-figure"><img src="assets/dep_bars_fixed_v12.png" alt="Modality roles Depression (large)"></div>
          <div class="back-text">
            <h4>What this shows</h4>
            <p>Linguistic markers dominate PHQ-8 grading. Audio adds robustness on short, disfluent
               turns, while micro-expressive facial AUs help around Mild↔Moderate boundaries—where
               presentations are mixed and ambiguity is highest.</p>
          </div>
        </div>
      </div>
    </div>
  </div>

  <!-- 3) Modality roles — PTSD -->
  <div class="card card-3d">
    <div class="card-inner">
      <div class="card-face card-front">
        <div class="media"><img src="assets/ptsd_bars_fixed_v12.png" alt="Modality contributions in PTSD"></div>
        <h3>Modality roles — PTSD</h3>
        <p class="muted">Text+Face strongest; audio–facial cues boost Severe detection.</p>
      </div>
      <div class="card-face card-back">
        <div class="back-wrap">
          <div class="back-figure"><img src="assets/ptsd_bars_fixed_v12.png" alt="Modality roles PTSD (large)"></div>
          <div class="back-text">
            <h4>What this shows</h4>
            <p>For PTSD, gaze/head-pose regularity and AU clusters, together with lexical content,
               strengthen separation—especially for Severe—where text alone saturates.</p>
          </div>
        </div>
      </div>
    </div>
  </div>

  <!-- 4) Per-class F1 — Depression -->
  <div class="card card-3d">
    <div class="card-inner">
      <div class="card-face card-front">
        <div class="media"><img src="assets/perclass_f1_XGB_DEP_ALL.png" alt="Per-class F1 (Depression)"></div>
        <h3>Per-class F1 — Depression</h3>
        <p class="muted">Extremes are easy; adjacent severities confuse more.</p>
      </div>
      <div class="card-face card-back">
        <div class="back-wrap">
          <div class="back-figure"><img src="assets/perclass_f1_XGB_DEP_ALL.png" alt="Per-class F1 Depression (large)"></div>
          <div class="back-text">
            <h4>What this shows</h4>
            <p>Minimal and Severe are reliably identified. Confusions are local (Mild↔Moderate,
               Moderate↔Mod-Severe), consistent with clinical ambiguity and overlapping symptom profiles.</p>
          </div>
        </div>
      </div>
    </div>
  </div>

  <!-- 5) Per-class F1 — PTSD -->
  <div class="card card-3d">
    <div class="card-inner">
      <div class="card-face card-front">
        <div class="media"><img src="assets/perclass_f1_XGB_PTSD_ALL.png" alt="Per-class F1 (PTSD)"></div>
        <h3>Per-class F1 — PTSD</h3>
        <p class="muted">Moderate stays challenging; Severe is sharper with fusion.</p>
      </div>
      <div class="card-face card-back">
        <div class="back-wrap">
          <div class="back-figure"><img src="assets/perclass_f1_XGB_PTSD_ALL.png" alt="Per-class F1 PTSD (large)"></div>
          <div class="back-text">
            <h4>What this shows</h4>
            <p>Fusion preserves sensitivity in Moderate while sharpening Severe—evidence that non-lexical
               arousal cues (prosody, micro-stability) complement text in PTSD grading.</p>
          </div>
        </div>
      </div>
    </div>
  </div>

  <!-- 6) Decision curve — Depression -->
  <div class="card card-3d">
    <div class="card-inner">
      <div class="card-face card-front">
        <div class="media"><img src="assets/decision_curve_DEP_fusion_xgb_perclass.png" alt="Decision curve (Depression)"></div>
        <h3>Decision-curve (Depression)</h3>
        <p class="muted">Higher net benefit across clinically relevant thresholds.</p>
      </div>
      <div class="card-face card-back">
        <div class="back-wrap">
          <div class="back-figure"><img src="assets/decision_curve_DEP_fusion_xgb_perclass.png" alt="Decision curve Depression (large)"></div>
          <div class="back-text">
            <h4>What this shows</h4>
            <p>Calibrated late-fusion probabilities yield better net benefit than unimodal baselines,
               suggesting fewer unnecessary escalations for similar hit-rates in stepped-care workflows.</p>
          </div>
        </div>
      </div>
    </div>
  </div>

  <!-- 7) Confusion matrix — Depression -->
  <div class="card card-3d">
    <div class="card-inner">
      <div class="card-face card-front">
        <div class="media"><img src="assets/pooled_cm_XGB_DEP_ALL.png" alt="Confusion matrix (Depression)"></div>
        <h3>Confusion — Depression</h3>
        <p class="muted">Errors cluster locally between adjacent PHQ-8 tiers.</p>
      </div>
      <div class="card-face card-back">
        <div class="back-wrap">
          <div class="back-figure"><img src="assets/pooled_cm_XGB_DEP_ALL.png" alt="Confusion matrix Depression (large)"></div>
          <div class="back-text">
            <h4>What this shows</h4>
            <p>Locality of errors is desirable for triage: near-misses often map to similar care pathways.
               Fusion reduces off-diagonal, non-local mistakes compared to unimodal heads.</p>
          </div>
        </div>
      </div>
    </div>
  </div>

  <!-- 8) Confusion matrix — PTSD -->
  <div class="card card-3d">
    <div class="card-inner">
      <div class="card-face card-front">
        <div class="media"><img src="assets/pooled_cm_XGB_PTSD_ALL.png" alt="Confusion matrix (PTSD)"></div>
        <h3>Confusion — PTSD</h3>
        <p class="muted">Severe separates; Mild vs Moderate retains overlap.</p>
      </div>
      <div class="card-face card-back">
        <div class="back-wrap">
          <div class="back-figure"><img src="assets/pooled_cm_XGB_PTSD_ALL.png" alt="Confusion matrix PTSD (large)"></div>
          <div class="back-text">
            <h4>What this shows</h4>
            <p>Overlap in low–mid tiers reflects neutral lexical content and short utterances; Severe
               benefits from audio–facial arousal patterns and posture/gaze regularity.</p>
          </div>
        </div>
      </div>
    </div>
  </div>

  <!-- 9) Unimodal failure (Audio-only example) -->
  <div class="card card-3d">
    <div class="card-inner">
      <div class="card-face card-front">
        <div class="media"><img src="assets/pooled_cm_XGB_DEP_AUDIO.png" alt="Unimodal failure (Audio-only)"></div>
        <h3>Unimodal Failure — Audio</h3>
        <p class="muted">Removing text collapses mid-tier precision.</p>
      </div>
      <div class="card-face card-back">
        <div class="back-wrap">
          <div class="back-figure"><img src="assets/pooled_cm_XGB_DEP_AUDIO.png" alt="Unimodal Audio-only (large)"></div>
          <div class="back-text">
            <h4>What this shows</h4>
            <p>Audio alone underfits PHQ-8 mid-tiers, motivating late-fusion calibration and
               disorder-specific heads that can gracefully degrade when streams are noisy/missing.</p>
          </div>
        </div>
      </div>
    </div>
  </div>

  <!-- 10) ROC — Depression -->
  <div class="card card-3d">
    <div class="card-inner">
      <div class="card-face card-front">
        <div class="media"><img src="assets/roc_XGB_DEP_ALL.png" alt="ROC (Depression)"></div>
        <h3>ROC — Depression</h3>
        <p class="muted">High AUC with balanced trade-offs across classes.</p>
      </div>
      <div class="card-face card-back">
        <div class="back-wrap">
          <div class="back-figure"><img src="assets/roc_XGB_DEP_ALL.png" alt="ROC Depression (large)"></div>
          <div class="back-text">
            <h4>What this shows</h4>
            <p>Complementary cues lift discrimination near borderline classes, aligning with PR/decision-curve
               gains and narrow CIs under stratified CV.</p>
          </div>
        </div>
      </div>
    </div>
  </div>

  <!-- 11) ROC — PTSD -->
  <div class="card card-3d">
    <div class="card-inner">
      <div class="card-face card-front">
        <div class="media"><img src="assets/roc_XGB_PTSD_ALL.png" alt="ROC (PTSD)"></div>
        <h3>ROC — PTSD</h3>
        <p class="muted">Robust separation; slightly flatter than PHQ-8.</p>
      </div>
      <div class="card-face card-back">
        <div class="back-wrap">
          <div class="back-figure"><img src="assets/roc_XGB_PTSD_ALL.png" alt="ROC PTSD (large)"></div>
          <div class="back-text">
            <h4>What this shows</h4>
            <p>Consistent AUC across folds; lingering overlap tracks the Mild↔Moderate confusion pattern
               observed in the matrix and embeddings.</p>
          </div>
        </div>
      </div>
    </div>
  </div>

  <!-- 12) SHAP — Depression -->
  <div class="card card-3d">
    <div class="card-inner">
      <div class="card-face card-front">
        <div class="media"><img src="assets/shap_DEP_fusion_xgb.png" alt="SHAP summary (Depression)"></div>
        <h3>Attribution — Depression</h3>
        <p class="muted">Language cues dominate; audio/face refine mid-tier splits.</p>
      </div>
      <div class="card-face card-back">
        <div class="back-wrap">
          <div class="back-figure"><img src="assets/shap_DEP_fusion_xgb.png" alt="SHAP Depression (large)"></div>
          <div class="back-text">
            <h4>What this shows</h4>
            <p>SHAP aligns with clinical theory: negative affect frames, self-referential style, and reduced
               lexical diversity drive PHQ-8; prosodic stability and AUs help Moderate vs Mod-Severe.</p>
          </div>
        </div>
      </div>
    </div>
  </div>

  <!-- 13) SHAP — PTSD -->
  <div class="card card-3d">
    <div class="card-inner">
      <div class="card-face card-front">
        <div class="media"><img src="assets/shap_PTSD_fusion_xgb.png" alt="SHAP summary (PTSD)"></div>
        <h3>Attribution — PTSD</h3>
        <p class="muted">Prosodic bursts & head-pose micro-stability are salient.</p>
      </div>
      <div class="card-face card-back">
        <div class="back-wrap">
          <div class="back-figure"><img src="assets/shap_PTSD_fusion_xgb.png" alt="SHAP PTSD (large)"></div>
          <div class="back-text">
            <h4>What this shows</h4>
            <p>Startle-like prosodic activity and stable head-pose/gaze increase importance for Severe PTSD,
               complementing lexical markers when text saturates.</p>
          </div>
        </div>
      </div>
    </div>
  </div>

  <!-- 14) Embedding geometry — PCA (DEP) -->
  <div class="card card-3d">
    <div class="card-inner">
      <div class="card-face card-front">
        <div class="media"><img src="assets/pca2d_DEP_ALL.png" alt="PCA embedding (Depression)"></div>
        <h3>Embedding — PCA (DEP)</h3>
        <p class="muted">Coarse gradients with mid-tier overlap.</p>
      </div>
      <div class="card-face card-back">
        <div class="back-wrap">
          <div class="back-figure"><img src="assets/pca2d_DEP_ALL.png" alt="PCA Depression (large)"></div>
          <div class="back-text">
            <h4>What this shows</h4>
            <p>Linear projections separate extremes; mid-tiers intermix—mirroring per-class F1 and indicating
               nuanced, mixed lexical–prosodic profiles.</p>
          </div>
        </div>
      </div>
    </div>
  </div>

  <!-- 15) Embedding geometry — t-SNE (PTSD) -->
  <div class="card card-3d">
    <div class="card-inner">
      <div class="card-face card-front">
        <div class="media"><img src="assets/tsne2d_PTSD_ALL.png" alt="t-SNE embedding (PTSD)"></div>
        <h3>Embedding — t-SNE (PTSD)</h3>
        <p class="muted">Dense Severe clusters; diffuse Mild regions.</p>
      </div>
      <div class="card-face card-back">
        <div class="back-wrap">
          <div class="back-figure"><img src="assets/tsne2d_PTSD_ALL.png" alt="t-SNE PTSD (large)"></div>
          <div class="back-text">
            <h4>What this shows</h4>
            <p>Non-linear neighborhoods expose compact Severe structure and spread-out Mild instances,
               matching the confusion pattern and modality analysis above.</p>
          </div>
        </div>
      </div>
    </div>
  </div>

</div>

<section id="results">
  <div class="container">
    <h2>Selected Results</h2>

    <!-- KPI strip (animated counters) -->
    <div class="kpis">
      <div class="kpi fade-in">
        <h4>Depression · TEXT (XGB)</h4>
        <div class="big"><span class="count" data-to="0.862">0.862</span> ACC</div>
        <small>F1w 0.860 · AUC 0.964</small>
      </div>
      <div class="kpi fade-in">
        <h4>PTSD · TEXT (XGB)</h4>
        <div class="big"><span class="count" data-to="0.862">0.862</span> ACC</div>
        <small>F1w 0.861 · AUC 0.971</small>
      </div>
      <div class="kpi fade-in">
        <h4>Depression · Fusion (ALL)</h4>
        <div class="big"><span class="count" data-to="0.852">0.852</span> ACC</div>
        <small>F1w 0.850 · AUC 0.961</small>
      </div>
      <div class="kpi fade-in">
        <h4>PTSD · Fusion (ALL)</h4>
        <div class="big"><span class="count" data-to="0.854">0.854</span> ACC</div>
        <small>F1w 0.854 · AUC 0.970</small>
      </div>
    </div>

    <!-- Why these matter -->
    <div class="reasons fade-in" style="margin-top:18px">
      <div class="reason">
        <strong>Fusion improves clinical utility.</strong> Decision-curve analysis shows higher net benefit across wide thresholds vs. unimodal baselines — ideal for threshold-based triage/stepped care.
        <span title="Higher net benefit across thresholds for both tasks">ℹ︎</span>
      </div>
      <div class="reason">
        <strong>Text is central; audio+face add robustness.</strong> Removing TEXT is the only ablation that materially drops ACC/F1; audio/face steady severe-case sensitivity and guard against missing/noisy streams.
      </div>
      <div class="reason">
        <strong>Error shape.</strong> Per-class F1 peaks at extremes (minimal / severe); mid-tiers remain hardest. PR shows strong recall at high precision for severe cases; ROC ≈ ceiling.
      </div>
    </div>

    <!-- Setup, now scannable -->
    <details class="accordion fade-in" style="margin-top:22px" open>
      <summary>Setup at a glance</summary>
      <div class="content">
        <div class="badges">
          <span class="badge brand">Encoders: Text 768-D · Audio 256-D · Face 512-D</span>
          <span class="badge">Fusion: concat → z-score per fold</span>
          <span class="badge">Classifier: XGBoost multi:softprob</span>
          <span class="badge">CV: stratified 5-fold · inverse class weights</span>
          <span class="badge">Metrics: ACC, F1w, AUC, MCC, κ, PR/ROC</span>
        </div>
        <div class="cols" style="margin-top:12px">
          <ul>
            <li><strong>Why this setup?</strong> Class imbalance handled by per-fold weights; out-of-fold probabilities used for metrics.</li>
            <li><strong>Robustness knobs.</strong> Late fusion stabilizes when one stream degrades (e.g., low-SNR audio).</li>
          </ul>
          <ul>
            <li><strong>Interpretability.</strong> SHAP: language dominates depression; prosody/facial expressivity support PTSD.</li>
            <li><strong>Where fusion helps.</strong> Net-benefit gains and severe-class sensitivity.</li>
          </ul>
        </div>
      </div>
    </details>

    <!-- Existing table kept, but visually framed as “Details” -->
    <details class="accordion fade-in" style="margin-top:16px">
      <summary>Cross-validated Performance (full table)</summary>
      <div class="content">
        <!-- keep your original table markup below -->
        <table class="table">
          <thead><tr><th>Task</th><th>Model</th><th>ACC</th><th>F1w</th><th>AUC</th></tr></thead>
          <tbody>
            <tr><td>Depression</td><td>TEXT (XGB)</td><td>0.862</td><td>0.860</td><td>0.964</td></tr>
            <tr><td>Depression</td><td>Fusion ALL (XGB)</td><td>0.852</td><td>0.850</td><td>0.961</td></tr>
            <tr><td>PTSD</td><td>TEXT (XGB)</td><td>0.862</td><td>0.861</td><td>0.971</td></tr>
            <tr><td>PTSD</td><td>Fusion ALL (XGB)</td><td>0.854</td><td>0.854</td><td>0.970</td></tr>
          </tbody>
        </table>
      </div>
    </details>
  </div>
</section>

<!-- ===== MANUSCRIPT (arXiv only) ===== -->
<section id="manuscript">
  <div class="container">
    <h2 class="section-title">Full Manuscript</h2>

    <div class="card">
      <p class="lead">
        Read the manuscript on arXiv and cite it using the BibTeX below.
      </p>

      <div class="cta-row" style="justify-content:flex-start">
        <a class="chip primary" href="https://arxiv.org/pdf/2510.20239.pdf" target="_blank" rel="noopener">
          Open arXiv PDF
        </a>
        <a class="chip" href="https://arxiv.org/abs/2510.20239" target="_blank" rel="noopener">
          arXiv abstract
        </a>
      </div>

      <!-- BibTeX (copy-ready) -->
      <h3 style="margin-top:18px">BibTeX</h3>
      <pre id="bibtex" style="margin:8px 0 12px; padding:12px; background:#f8f9ff; border:1px solid rgba(15,36,65,.10); border-radius:12px; overflow:auto"></pre>
      <button class="chip" id="copy-bib" type="button" aria-label="Copy BibTeX">Copy BibTeX</button>
    </div>
  </div>
</section>

<script>
(() => {
  const bib = `@misc{cenacchi2025trimodalseverityfuseddiagnosis,
  title={Tri-Modal Severity Fused Diagnosis across Depression and Post-traumatic Stress Disorders},
  author={Filippo Cenacchi and Deborah Richards and Longbing Cao},
  year={2025},
  eprint={2510.20239},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2510.20239},
}`;
  const pre = document.getElementById('bibtex');
  if (pre) pre.textContent = bib;

  const copyBtn = document.getElementById('copy-bib');
  if (copyBtn && navigator.clipboard) {
    copyBtn.addEventListener('click', async () => {
      try {
        await navigator.clipboard.writeText(bib);
        copyBtn.textContent = 'Copied ✓';
        setTimeout(() => (copyBtn.textContent = 'Copy BibTeX'), 1200);
      } catch {}
    });
  }
})();
</script>


<script>
// simple fade-in on scroll
const io = new IntersectionObserver(es=>es.forEach(e=>{
  if(e.isIntersecting) e.target.classList.add('show');
}), {threshold:.15});
document.querySelectorAll('.fade-in').forEach(el=>io.observe(el));

// animated KPI counters
function animateCount(el){
  const to = parseFloat(el.dataset.to); if(isNaN(to)) return;
  let cur = 0; const step = to/30;
  const tick = ()=>{ cur = Math.min(to, cur+step); el.textContent = cur.toFixed(3); if(cur<to) requestAnimationFrame(tick); };
  tick();
}
document.querySelectorAll('.count').forEach(animateCount);
</script>


  <!-- ===== LIGHTBOX (no dark page) ===== -->
  <div class="lightbox" id="lightbox" aria-hidden="true">
    <button class="close" aria-label="Close">Close ✕</button>
    <img src="" alt="">
  </div>

  <!-- ===== FOOTER ===== -->
  <footer>
    <div class="container">
      <div>© 2025 Filippo Cenacchi · <a class="inline" href="#top">Back to top</a></div>
    </div>
  </footer>
  <script>
(async ()=>{
  const url = 'assets/paper.pdf';
  const shell = document.getElementById('pdf-shell');
  const frame = document.getElementById('pdf-frame');
  const fallback = document.getElementById('pdf-fallback');

  try {
    const res = await fetch(url, { method: 'HEAD', cache: 'no-store' });
    const isPDF = res.ok && (res.headers.get('content-type')||'').includes('pdf');
    if (!isPDF) throw new Error('Not a PDF or missing');

    // Only set src after confirming it exists (prevents the Chrome “Failed to load” pane)
    frame.src = url + '#view=FitH';
    shell.hidden = false;
    fallback.hidden = true;
  } catch (e) {
    // Clean fallback — no iframe, no error UI
    shell.hidden = true;
    fallback.hidden = false;
  }
})();
</script>

      <script>
  (function(){
    const grid = document.querySelector('.cards');
    if(!grid) return;

    const onEnter = e => { if(e.target.classList.contains('card-3d')) document.documentElement.style.overflow='hidden'; };
    const onLeave = e => { if(e.target.classList.contains('card-3d')) document.documentElement.style.overflow=''; };

    grid.addEventListener('pointerenter', onEnter, true);
    grid.addEventListener('pointerleave', onLeave, true);
  })();
</script>

  <script>
    // Lightbox without dark scrim
    const lb = document.getElementById('lightbox');
    const lbImg = lb.querySelector('img');
    document.querySelectorAll('[data-zoom]').forEach(img=>{
      img.style.cursor='zoom-in';
      img.addEventListener('click', ()=>{
        lbImg.src = img.src;
        lb.classList.add('open');
        lb.setAttribute('aria-hidden','false');
      });
    });
    lb.addEventListener('click', (e)=>{
      if(e.target===lb || e.target.classList.contains('close')){
        lb.classList.remove('open');
        lb.setAttribute('aria-hidden','true');
        lbImg.src='';
      }
    });

    // Ensure hero arch loads crisp
    const arch = document.getElementById('arch-img');
    arch.addEventListener('error',()=>{ arch.alt = "Add your architecture image to assets/Diagram.png"; });
  </script>
</body>
</html>
